#!/usr/bin/env python3
"""
äº‹ä»¶/æ–°é—»æ•°æ®è·å–å·¥å…·

æ”¯æŒå¤šä¸ªæ•°æ®æºï¼š
1. æ¸¯äº¤æ‰€æŠ«éœ²æ˜“ï¼ˆå…¬å¸å…¬å‘Šï¼‰
2. æ–°æµªè´¢ç»ï¼ˆæ–°é—»ï¼‰
3. ä¸œæ–¹è´¢å¯Œï¼ˆæ–°é—»+ç ”æŠ¥ï¼‰
4. Brave Search APIï¼ˆå…¨ç½‘æœç´¢ï¼‰

ä½¿ç”¨æ–¹æ³•:
    python fetch_events.py 02513 --start 2026-01-01
    python fetch_events.py 02513 --source hkex
    python fetch_events.py --search "æ™ºè°±AI é¢†å¯¼äºº"
"""

import sys
import json
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import os

try:
    import requests
except ImportError:
    print("éœ€è¦å®‰è£…ä¾èµ–: pip install requests")
    sys.exit(1)


# ============== 1. æ¸¯äº¤æ‰€æŠ«éœ²æ˜“ï¼ˆå…¬å¸å…¬å‘Šï¼‰==============

def get_hkex_announcements(
    stock_code: str,
    start_date: str = None,
    end_date: str = None,
    lang: str = "ZH"
) -> List[Dict]:
    """
    ä»æ¸¯äº¤æ‰€æŠ«éœ²æ˜“è·å–å…¬å¸å…¬å‘Š

    API: https://www1.hkexnews.hk/search/titlesearch.xhtml

    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 02513ï¼‰
        start_date: å¼€å§‹æ—¥æœŸ YYYY-MM-DD
        end_date: ç»“æŸæ—¥æœŸ YYYY-MM-DD
        lang: è¯­è¨€ ZH/EN

    Returns:
        å…¬å‘Šåˆ—è¡¨
    """
    stock_code = stock_code.replace('.HK', '').zfill(5)

    url = "https://www1.hkexnews.hk/search/titlesearch.xhtml"

    # æ„å»ºæœç´¢å‚æ•°
    params = {
        "lang": lang,
        "category": 0,  # æ‰€æœ‰ç±»åˆ«
        "market": "SEHK",
        "searchType": 0,
        "t1code": 40000,  # ä¸Šå¸‚å…¬å¸å…¬å‘Š
        "t2Gcode": -2,
        "t2code": -2,
        "stockId": stock_code,
        "from": start_date.replace('-', '') if start_date else "",
        "to": end_date.replace('-', '') if end_date else "",
        "MB-Ede": "",
        "mession": ""
    }

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        "Referer": "https://www1.hkexnews.hk/search/titlesearch.xhtml"
    }

    try:
        resp = requests.get(url, params=params, headers=headers, timeout=15)

        # æ¸¯äº¤æ‰€è¿”å›HTMLï¼Œéœ€è¦è§£æ
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œè¿”å›åŸå§‹å“åº”ä¾›åç»­è§£æ
        announcements = []

        # å°è¯•æå–å…¬å‘Šé“¾æ¥
        pattern = r'<a[^>]*href="([^"]*)"[^>]*>([^<]*)</a>'
        matches = re.findall(pattern, resp.text)

        for href, title in matches:
            if 'listedco' in href or '.pdf' in href:
                announcements.append({
                    'title': title.strip(),
                    'url': href if href.startswith('http') else f"https://www1.hkexnews.hk{href}",
                    'source': 'hkex'
                })

        return announcements

    except Exception as e:
        return [{"error": f"æ¸¯äº¤æ‰€APIè¯·æ±‚å¤±è´¥: {e}"}]


# ============== 2. ä¸œæ–¹è´¢å¯Œæ–°é—» ==============

def get_eastmoney_news(
    stock_code: str,
    page: int = 1,
    page_size: int = 20
) -> List[Dict]:
    """
    ä»ä¸œæ–¹è´¢å¯Œè·å–è‚¡ç¥¨æ–°é—»

    API: https://search-api-web.eastmoney.com/search/jsonp

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        page: é¡µç 
        page_size: æ¯é¡µæ•°é‡

    Returns:
        æ–°é—»åˆ—è¡¨
    """
    stock_code = stock_code.replace('.HK', '').zfill(5)

    # ä¸œæ–¹è´¢å¯Œæœç´¢API
    url = "https://search-api-web.eastmoney.com/search/jsonp"

    params = {
        "cb": "jQuery_callback",
        "param": json.dumps({
            "uid": "",
            "keyword": stock_code,
            "type": ["cmsArticleWebOld"],  # æ–°é—»æ–‡ç« 
            "client": "web",
            "clientType": "web",
            "clientVersion": "curr",
            "param": {
                "cmsArticleWebOld": {
                    "searchScope": "default",
                    "sort": "time",  # æŒ‰æ—¶é—´æ’åº
                    "pageIndex": page,
                    "pageSize": page_size,
                    "preTag": "",
                    "postTag": ""
                }
            }
        })
    }

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": "https://so.eastmoney.com/"
    }

    try:
        resp = requests.get(url, params=params, headers=headers, timeout=15)

        # è§£æJSONPå“åº”
        json_str = re.search(r'jQuery_callback\((.*)\)', resp.text)
        if not json_str:
            return [{"error": "æ— æ³•è§£æä¸œæ–¹è´¢å¯Œå“åº”"}]

        data = json.loads(json_str.group(1))
        articles = data.get('result', {}).get('cmsArticleWebOld', [])

        news_list = []
        for article in articles:
            news_list.append({
                'title': article.get('title', ''),
                'date': article.get('date', ''),
                'url': article.get('url', ''),
                'source': 'eastmoney',
                'summary': article.get('content', '')[:200] if article.get('content') else ''
            })

        return news_list

    except Exception as e:
        return [{"error": f"ä¸œæ–¹è´¢å¯ŒAPIè¯·æ±‚å¤±è´¥: {e}"}]


# ============== 3. æ–°æµªè´¢ç»æ¸¯è‚¡æ–°é—» ==============

def get_sina_hk_news(
    stock_code: str,
    page: int = 1
) -> List[Dict]:
    """
    ä»æ–°æµªè´¢ç»è·å–æ¸¯è‚¡æ–°é—»

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        page: é¡µç 

    Returns:
        æ–°é—»åˆ—è¡¨
    """
    stock_code = stock_code.replace('.HK', '').zfill(5)

    url = f"https://vip.stock.finance.sina.com.cn/corp/go.php/vCB_AllNewsStock/symbol/hk{stock_code}/type/news.phtml"

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": "https://finance.sina.com.cn"
    }

    try:
        resp = requests.get(url, headers=headers, timeout=15)
        resp.encoding = 'gbk'

        news_list = []

        # ç®€å•è§£æHTMLæå–æ–°é—»é“¾æ¥
        # æ ¼å¼: <a href="...">æ–°é—»æ ‡é¢˜</a> <span>æ—¥æœŸ</span>
        pattern = r'<a[^>]*href="([^"]*)"[^>]*target="_blank"[^>]*>([^<]+)</a>'
        matches = re.findall(pattern, resp.text)

        for href, title in matches[:20]:  # é™åˆ¶20æ¡
            if 'finance.sina' in href or 'stock.sina' in href:
                news_list.append({
                    'title': title.strip(),
                    'url': href,
                    'source': 'sina'
                })

        return news_list

    except Exception as e:
        return [{"error": f"æ–°æµªè´¢ç»è¯·æ±‚å¤±è´¥: {e}"}]


# ============== 4. Brave Search API ==============

def search_brave(
    query: str,
    count: int = 10,
    freshness: str = None
) -> List[Dict]:
    """
    ä½¿ç”¨Brave Search APIæœç´¢

    éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ BRAVE_API_KEY

    Args:
        query: æœç´¢å…³é”®è¯
        count: ç»“æœæ•°é‡
        freshness: æ—¶é—´èŒƒå›´ (pd=past day, pw=past week, pm=past month)

    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    api_key = os.environ.get('BRAVE_API_KEY')

    if not api_key:
        return [{"error": "æœªè®¾ç½® BRAVE_API_KEY ç¯å¢ƒå˜é‡"}]

    url = "https://api.search.brave.com/res/v1/web/search"

    headers = {
        "Accept": "application/json",
        "X-Subscription-Token": api_key
    }

    params = {
        "q": query,
        "count": count,
        "search_lang": "zh-hans",
        "country": "cn"
    }

    if freshness:
        params["freshness"] = freshness

    try:
        resp = requests.get(url, headers=headers, params=params, timeout=15)

        if resp.status_code == 401:
            return [{"error": "Brave API Key æ— æ•ˆ"}]

        data = resp.json()
        results = data.get('web', {}).get('results', [])

        search_results = []
        for r in results:
            search_results.append({
                'title': r.get('title', ''),
                'url': r.get('url', ''),
                'description': r.get('description', ''),
                'date': r.get('age', ''),
                'source': 'brave'
            })

        return search_results

    except Exception as e:
        return [{"error": f"Brave Searchè¯·æ±‚å¤±è´¥: {e}"}]


# ============== 5. ç»¼åˆäº‹ä»¶æœç´¢ ==============

def search_stock_events(
    stock_code: str,
    keywords: List[str] = None,
    start_date: str = None,
    sources: List[str] = None
) -> Dict:
    """
    ç»¼åˆæœç´¢è‚¡ç¥¨ç›¸å…³äº‹ä»¶

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        keywords: é¢å¤–å…³é”®è¯ï¼ˆå¦‚ "é¢†å¯¼äºº", "æ¨¡å‹å‘å¸ƒ"ï¼‰
        start_date: å¼€å§‹æ—¥æœŸ
        sources: æ•°æ®æºåˆ—è¡¨

    Returns:
        ç»¼åˆæœç´¢ç»“æœ
    """
    if sources is None:
        sources = ['eastmoney', 'sina', 'brave']

    if keywords is None:
        keywords = []

    results = {
        'stock_code': stock_code,
        'search_time': datetime.now().strftime('%Y-%m-%d %H:%M'),
        'announcements': [],
        'news': [],
        'search_results': []
    }

    stock_code_clean = stock_code.replace('.HK', '').zfill(5)

    # 1. è·å–å…¬å¸å…¬å‘Š
    print(f"ğŸ“¢ è·å–æ¸¯äº¤æ‰€å…¬å‘Š...")
    announcements = get_hkex_announcements(stock_code_clean, start_date)
    if announcements and 'error' not in announcements[0]:
        results['announcements'] = announcements[:10]

    # 2. è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»
    if 'eastmoney' in sources:
        print(f"ğŸ“° è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»...")
        em_news = get_eastmoney_news(stock_code_clean)
        if em_news and 'error' not in em_news[0]:
            results['news'].extend(em_news)

    # 3. è·å–æ–°æµªæ–°é—»
    if 'sina' in sources:
        print(f"ğŸ“° è·å–æ–°æµªè´¢ç»æ–°é—»...")
        sina_news = get_sina_hk_news(stock_code_clean)
        if sina_news and 'error' not in sina_news[0]:
            results['news'].extend(sina_news)

    # 4. Braveæœç´¢å…³é”®äº‹ä»¶
    if 'brave' in sources and os.environ.get('BRAVE_API_KEY'):
        print(f"ğŸ” Braveæœç´¢å…³é”®äº‹ä»¶...")

        # æœç´¢è‚¡ç¥¨åç§°+å…³é”®è¯
        base_keywords = ["æ™ºè°±AI", "02513"]
        event_keywords = ["é¢†å¯¼äºº", "æ¨¡å‹å‘å¸ƒ", "æ”¿ç­–", "åˆä½œ", "èèµ„"]

        for kw in event_keywords + keywords:
            query = f"{base_keywords[0]} {kw}"
            brave_results = search_brave(query, count=5, freshness="pm")
            if brave_results and 'error' not in brave_results[0]:
                for r in brave_results:
                    r['keyword'] = kw
                results['search_results'].extend(brave_results)

    # å»é‡
    seen_urls = set()
    unique_news = []
    for news in results['news']:
        if news.get('url') and news['url'] not in seen_urls:
            seen_urls.add(news['url'])
            unique_news.append(news)
    results['news'] = unique_news

    return results


# ============== äº‹ä»¶æå–ä¸åˆ†ç±» ==============

def extract_event_timeline(results: Dict) -> List[Dict]:
    """
    ä»æœç´¢ç»“æœä¸­æå–äº‹ä»¶æ—¶é—´çº¿

    Args:
        results: search_stock_events çš„è¿”å›ç»“æœ

    Returns:
        äº‹ä»¶æ—¶é—´çº¿
    """
    events = []

    # å®šä¹‰äº‹ä»¶å…³é”®è¯åˆ†ç±»
    event_categories = {
        'æ¨¡å‹å‘å¸ƒ': ['å‘å¸ƒ', 'æ¨¡å‹', 'GLM', 'ç‰ˆæœ¬', 'å‡çº§', 'å¼€æº'],
        'é¢†å¯¼äººä¼šè§': ['é¢†å¯¼', 'æ€»ç†', 'ä¸»å¸­', 'ä¼šè§', 'è°ƒç ”', 'è§†å¯Ÿ'],
        'æ”¿ç­–åˆ©å¥½': ['æ”¿ç­–', 'æ”¯æŒ', 'è¡¥è´´', 'æˆ˜ç•¥', 'è§„åˆ’', 'æŒ‡å¯¼æ„è§'],
        'åˆä½œç­¾çº¦': ['åˆä½œ', 'ç­¾çº¦', 'æˆ˜ç•¥', 'åè®®', 'æºæ‰‹'],
        'èèµ„åŠ¨æ€': ['èèµ„', 'æŠ•èµ„', 'ä¼°å€¼', 'å…¥è‚¡'],
        'äº§å“å‘å¸ƒ': ['äº§å“', 'åº”ç”¨', 'ä¸Šçº¿', 'å‘å¸ƒä¼š'],
        'ä¸šç»©ç›¸å…³': ['ä¸šç»©', 'è¥æ”¶', 'åˆ©æ¶¦', 'è´¢æŠ¥', 'ç›ˆåˆ©']
    }

    # å¤„ç†æ–°é—»
    for news in results.get('news', []):
        title = news.get('title', '')
        category = 'å…¶ä»–'

        for cat, keywords in event_categories.items():
            if any(kw in title for kw in keywords):
                category = cat
                break

        events.append({
            'title': title,
            'category': category,
            'date': news.get('date', ''),
            'url': news.get('url', ''),
            'source': news.get('source', '')
        })

    # å¤„ç†æœç´¢ç»“æœ
    for result in results.get('search_results', []):
        title = result.get('title', '')
        category = result.get('keyword', 'å…¶ä»–')

        events.append({
            'title': title,
            'category': category,
            'date': result.get('date', ''),
            'url': result.get('url', ''),
            'source': 'brave'
        })

    return events


# ============== CLI ==============

def print_results(results: Dict):
    """æ‰“å°æœç´¢ç»“æœ"""
    print("\n" + "="*70)
    print(f"  {results['stock_code']} äº‹ä»¶/æ–°é—»æœç´¢ç»“æœ")
    print("="*70)
    print(f"æœç´¢æ—¶é—´: {results['search_time']}")

    # å…¬å‘Š
    if results['announcements']:
        print(f"\nğŸ“¢ æ¸¯äº¤æ‰€å…¬å‘Š ({len(results['announcements'])}æ¡):")
        print("-"*70)
        for ann in results['announcements'][:5]:
            print(f"  â€¢ {ann['title'][:50]}...")

    # æ–°é—»
    if results['news']:
        print(f"\nğŸ“° ç›¸å…³æ–°é—» ({len(results['news'])}æ¡):")
        print("-"*70)
        for news in results['news'][:10]:
            date_str = f"[{news['date']}]" if news.get('date') else ""
            print(f"  {date_str} {news['title'][:50]}...")
            print(f"    â””â”€ {news['url']}")

    # æœç´¢ç»“æœ
    if results['search_results']:
        print(f"\nğŸ” å…³é”®äº‹ä»¶æœç´¢ ({len(results['search_results'])}æ¡):")
        print("-"*70)
        for r in results['search_results'][:10]:
            kw = f"[{r.get('keyword', '')}]" if r.get('keyword') else ""
            print(f"  {kw} {r['title'][:45]}...")
            print(f"    â””â”€ {r['url']}")

    print("\n" + "="*70)


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='è‚¡ç¥¨äº‹ä»¶/æ–°é—»æ•°æ®è·å–å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ•°æ®æºè¯´æ˜:
  hkex       æ¸¯äº¤æ‰€æŠ«éœ²æ˜“ï¼ˆå…¬å¸å…¬å‘Šï¼‰
  eastmoney  ä¸œæ–¹è´¢å¯Œï¼ˆæ–°é—»+ç ”æŠ¥ï¼‰
  sina       æ–°æµªè´¢ç»ï¼ˆæ¸¯è‚¡æ–°é—»ï¼‰
  brave      Brave Search APIï¼ˆå…¨ç½‘æœç´¢ï¼Œéœ€è®¾ç½®BRAVE_API_KEYï¼‰

ç¤ºä¾‹:
  python fetch_events.py 02513
  python fetch_events.py 02513 --start 2026-01-01
  python fetch_events.py --search "æ™ºè°±AI é¢†å¯¼äººä¼šè§"

è®¾ç½®Brave API:
  export BRAVE_API_KEY=your_api_key_here
        """
    )

    parser.add_argument('ticker', nargs='?', help='è‚¡ç¥¨ä»£ç  (å¦‚ 02513)')
    parser.add_argument('--start', '-s', help='å¼€å§‹æ—¥æœŸ YYYY-MM-DD')
    parser.add_argument('--search', help='ç›´æ¥æœç´¢å…³é”®è¯')
    parser.add_argument('--source', nargs='+',
                        choices=['hkex', 'eastmoney', 'sina', 'brave'],
                        help='æŒ‡å®šæ•°æ®æº')
    parser.add_argument('--json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')

    args = parser.parse_args()

    # ç›´æ¥æœç´¢æ¨¡å¼
    if args.search:
        if not os.environ.get('BRAVE_API_KEY'):
            print("âŒ ç›´æ¥æœç´¢éœ€è¦è®¾ç½® BRAVE_API_KEY")
            print("   export BRAVE_API_KEY=your_api_key_here")
            sys.exit(1)

        print(f"ğŸ” æœç´¢: {args.search}")
        results = search_brave(args.search, count=20)

        if args.json:
            print(json.dumps(results, ensure_ascii=False, indent=2))
        else:
            for r in results:
                if 'error' in r:
                    print(f"âŒ {r['error']}")
                else:
                    print(f"\nâ€¢ {r['title']}")
                    print(f"  {r['description'][:100]}...")
                    print(f"  {r['url']}")
        return

    # è‚¡ç¥¨äº‹ä»¶æœç´¢
    if not args.ticker:
        parser.print_help()
        sys.exit(1)

    sources = args.source if args.source else ['eastmoney', 'sina']

    # å¦‚æœè®¾ç½®äº†Brave API Keyï¼Œè‡ªåŠ¨åŠ å…¥
    if os.environ.get('BRAVE_API_KEY') and 'brave' not in sources:
        sources.append('brave')

    results = search_stock_events(
        args.ticker,
        start_date=args.start,
        sources=sources
    )

    if args.json:
        print(json.dumps(results, ensure_ascii=False, indent=2, default=str))
    else:
        print_results(results)


if __name__ == "__main__":
    main()
