#!/usr/bin/env python3
"""
æ”¿ç­–/é¢†å¯¼äººè¡Œç¨‹ç›‘æ§å·¥å…·

å‰ç½®åˆ†ææ ¸å¿ƒï¼šæå‰å‘ç°æ”¿ç­–å‚¬åŒ–äº‹ä»¶

åŠŸèƒ½:
1. é¢†å¯¼äººè¡Œç¨‹è¿½è¸ª (æ–°åç½‘ã€äººæ°‘ç½‘)
2. æ”¿ç­–æ–‡ä»¶ç›‘æ§ (å›½åŠ¡é™¢ã€å‘æ”¹å§”ç­‰)
3. åº§è°ˆä¼šå‚ä¸è€…è¿½è¸ª
4. åˆ›å§‹äººåŠ¨æ€ç›‘æ§

ä½¿ç”¨æ–¹æ³•:
    python policy_monitor.py --leader          # é¢†å¯¼äººè¡Œç¨‹
    python policy_monitor.py --policy          # æ”¿ç­–æ–‡ä»¶
    python policy_monitor.py --founder å”æ°    # åˆ›å§‹äººè¿½è¸ª
    python policy_monitor.py --meeting         # åº§è°ˆä¼šç›‘æ§
"""

import sys
import json
import re
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional

try:
    import requests
except ImportError:
    print("éœ€è¦å®‰è£…ä¾èµ–: pip install requests")
    sys.exit(1)


# ============== 1. é¢†å¯¼äººè¡Œç¨‹è¿½è¸ª ==============

def get_leader_activities(days: int = 7) -> List[Dict]:
    """
    ä»æ–°åç½‘è·å–é¢†å¯¼äººè¿‘æœŸæ´»åŠ¨

    ç›‘æ§å…³é”®è¯: è€ƒå¯Ÿã€è§†å¯Ÿã€è°ƒç ”ã€åº§è°ˆã€ä¼šè§
    """
    results = []

    # æ–°åç½‘é¢†å¯¼äººæ´»åŠ¨é¡µ
    urls = [
        "https://www.news.cn/politics/leaders/xijinping/index.htm",
        "https://www.news.cn/politics/leaders/likeqiang/index.htm",
    ]

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
    }

    keywords = ['è€ƒå¯Ÿ', 'è§†å¯Ÿ', 'è°ƒç ”', 'åº§è°ˆ', 'ä¼šè§', 'å‡ºå¸­', 'ä¸»æŒ']
    tech_keywords = ['ç§‘æŠ€', 'äººå·¥æ™ºèƒ½', 'AI', 'åˆ›æ–°', 'ä¿¡åˆ›', 'ä¼ä¸š', 'å›­åŒº']

    for url in urls:
        try:
            resp = requests.get(url, headers=headers, timeout=15)
            resp.encoding = 'utf-8'

            # ç®€å•æå–æ–°é—»é“¾æ¥å’Œæ ‡é¢˜
            pattern = r'<a[^>]*href="([^"]*)"[^>]*>([^<]+)</a>'
            matches = re.findall(pattern, resp.text)

            for href, title in matches:
                # è¿‡æ»¤å…³é”®è¯
                if any(kw in title for kw in keywords):
                    is_tech_related = any(tk in title for tk in tech_keywords)
                    results.append({
                        'title': title.strip(),
                        'url': href if href.startswith('http') else f"https://www.news.cn{href}",
                        'is_tech_related': is_tech_related,
                        'priority': 'HIGH' if is_tech_related else 'NORMAL'
                    })

        except Exception as e:
            print(f"è·å– {url} å¤±è´¥: {e}")

    return results[:20]  # é™åˆ¶æ•°é‡


def search_leader_tech_visits(query: str = None) -> List[Dict]:
    """
    æœç´¢é¢†å¯¼äººç§‘æŠ€ä¼ä¸š/å›­åŒºè§†å¯Ÿè®°å½•

    ç”¨äºå‰ç½®åˆ†æï¼šå“ªäº›ä¼ä¸šæ›¾è¢«è§†å¯Ÿï¼Ÿ
    """
    from fetch_events import search_brave

    if query is None:
        query = "ä¹ è¿‘å¹³ è€ƒå¯Ÿ ç§‘æŠ€ä¼ä¸š 2026"

    results = search_brave(query, count=20)

    # è¿‡æ»¤å’Œæ ‡æ³¨
    filtered = []
    for r in results:
        if 'error' not in r:
            title = r.get('title', '')
            # æ£€æµ‹æ˜¯å¦æ¶‰åŠå…·ä½“ä¼ä¸š
            companies = extract_company_names(title + ' ' + r.get('description', ''))
            r['mentioned_companies'] = companies
            r['has_company'] = len(companies) > 0
            filtered.append(r)

    return filtered


def extract_company_names(text: str) -> List[str]:
    """ä»æ–‡æœ¬ä¸­æå–å…¬å¸åç§°"""
    # AIå¤§æ¨¡å‹å…¬å¸åˆ—è¡¨
    known_companies = [
        'æ™ºè°±', 'ç™¾åº¦', 'é˜¿é‡Œ', 'è…¾è®¯', 'åä¸º', 'å­—èŠ‚', 'å•†æ±¤',
        'DeepSeek', 'æœˆä¹‹æš—é¢', 'Moonshot', 'é›¶ä¸€ä¸‡ç‰©', 'ç™¾å·',
        'ç§‘å¤§è®¯é£', 'æ—·è§†', 'äº‘ä»', 'ä¾å›¾', 'å¯’æ­¦çºª', 'åœ°å¹³çº¿'
    ]

    found = []
    for company in known_companies:
        if company.lower() in text.lower():
            found.append(company)

    return found


# ============== 2. æ”¿ç­–æ–‡ä»¶ç›‘æ§ ==============

def get_policy_updates(keywords: List[str] = None) -> List[Dict]:
    """
    è·å–è¿‘æœŸæ”¿ç­–æ–‡ä»¶

    æ¥æº: å›½åŠ¡é™¢ã€å‘æ”¹å§”ã€å·¥ä¿¡éƒ¨ã€ç§‘æŠ€éƒ¨
    """
    if keywords is None:
        keywords = ['äººå·¥æ™ºèƒ½', 'å¤§æ¨¡å‹', 'ä¿¡åˆ›', 'ç§‘æŠ€åˆ›æ–°']

    results = []

    # æ”¿ç­–æ¥æº
    sources = [
        {
            'name': 'å›½åŠ¡é™¢',
            'url': 'https://www.gov.cn/zhengce/zuixin.htm',
        },
        {
            'name': 'å·¥ä¿¡éƒ¨',
            'url': 'https://www.miit.gov.cn/gzcy/zcwj/index.html',
        },
    ]

    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    for source in sources:
        try:
            resp = requests.get(source['url'], headers=headers, timeout=15)
            resp.encoding = 'utf-8'

            # æå–æ”¿ç­–é“¾æ¥
            pattern = r'<a[^>]*href="([^"]*)"[^>]*>([^<]+)</a>'
            matches = re.findall(pattern, resp.text)

            for href, title in matches[:30]:
                # å…³é”®è¯è¿‡æ»¤
                if any(kw in title for kw in keywords):
                    results.append({
                        'title': title.strip(),
                        'url': href,
                        'source': source['name'],
                        'keywords_matched': [kw for kw in keywords if kw in title]
                    })

        except Exception as e:
            print(f"è·å– {source['name']} å¤±è´¥: {e}")

    return results


# ============== 3. åº§è°ˆä¼šå‚ä¸è€…è¿½è¸ª ==============

def search_meeting_participants(meeting_type: str = "æ€»ä¹¦è®°åº§è°ˆä¼š") -> List[Dict]:
    """
    æœç´¢é‡è¦ä¼šè®®å‚ä¸è€…

    ç”¨äºè¿½è¸ªï¼šå“ªäº›ä¼ä¸šå®¶å‚ä¸è¿‡é«˜å±‚åº§è°ˆï¼Ÿ
    """
    from fetch_events import search_brave

    queries = [
        f"{meeting_type} ä¼ä¸šå®¶ å‚ä¸",
        f"{meeting_type} ç§‘æŠ€ä¼ä¸š è´Ÿè´£äºº",
        f"ä¹ è¿‘å¹³ åº§è°ˆ ä¼ä¸šå®¶ åå•",
    ]

    all_results = []
    for query in queries:
        results = search_brave(query, count=10)
        for r in results:
            if 'error' not in r:
                r['query'] = query
                all_results.append(r)

    return all_results


def track_founder_meetings(founder_name: str) -> List[Dict]:
    """
    è¿½è¸ªç‰¹å®šåˆ›å§‹äººçš„é«˜å±‚ä¼šè®®å‚ä¸è®°å½•

    ç¤ºä¾‹: track_founder_meetings("å”æ°")
    """
    from fetch_events import search_brave

    queries = [
        f"{founder_name} æ€»ä¹¦è®° åº§è°ˆ",
        f"{founder_name} ä¹ è¿‘å¹³",
        f"{founder_name} é¢†å¯¼äºº ä¼šè§",
        f"{founder_name} æ”¿åºœ äº¤æµ",
    ]

    all_results = []
    for query in queries:
        results = search_brave(query, count=5)
        for r in results:
            if 'error' not in r:
                r['founder'] = founder_name
                r['query'] = query
                all_results.append(r)

    # å»é‡
    seen = set()
    unique = []
    for r in all_results:
        if r['url'] not in seen:
            seen.add(r['url'])
            unique.append(r)

    return unique


# ============== 4. åˆ›å§‹äººåŠ¨æ€ç›‘æ§ ==============

def get_founder_news(founder_name: str, company_name: str = None) -> List[Dict]:
    """
    è·å–åˆ›å§‹äººè¿‘æœŸåŠ¨æ€

    ç›‘æ§: æ¼”è®²ã€é‡‡è®¿ã€è·å¥–ã€å‚ä¼šç­‰
    """
    from fetch_events import search_brave

    queries = [
        f"{founder_name} æ¼”è®²",
        f"{founder_name} é‡‡è®¿",
        f"{founder_name} è·å¥–",
        f"{founder_name} å‚ä¼š",
    ]

    if company_name:
        queries.append(f"{founder_name} {company_name}")

    all_results = []
    for query in queries:
        results = search_brave(query, count=5, freshness="pm")  # æœ€è¿‘ä¸€ä¸ªæœˆ
        for r in results:
            if 'error' not in r:
                r['query'] = query
                all_results.append(r)

    return all_results


# ============== 5. ç»¼åˆç›‘æ§æŠ¥å‘Š ==============

def generate_daily_report(tickers: List[str] = None) -> Dict:
    """
    ç”Ÿæˆæ¯æ—¥ç›‘æ§æŠ¥å‘Š

    æ•´åˆ: é¢†å¯¼äººè¡Œç¨‹ + æ”¿ç­–æ–‡ä»¶ + åˆ›å§‹äººåŠ¨æ€
    """
    report = {
        'date': datetime.now().strftime('%Y-%m-%d'),
        'leader_activities': [],
        'policy_updates': [],
        'founder_news': [],
        'signals': []
    }

    print("ğŸ“¡ è·å–é¢†å¯¼äººè¡Œç¨‹...")
    report['leader_activities'] = get_leader_activities()

    print("ğŸ“œ è·å–æ”¿ç­–æ›´æ–°...")
    report['policy_updates'] = get_policy_updates()

    # ç”Ÿæˆä¿¡å·
    for activity in report['leader_activities']:
        if activity.get('is_tech_related'):
            report['signals'].append({
                'type': 'LEADER_TECH_VISIT',
                'priority': 'HIGH',
                'title': activity['title'],
                'url': activity['url'],
                'action': 'å…³æ³¨ç›¸å…³AI/ç§‘æŠ€è‚¡'
            })

    for policy in report['policy_updates']:
        if len(policy.get('keywords_matched', [])) >= 2:
            report['signals'].append({
                'type': 'POLICY_UPDATE',
                'priority': 'MEDIUM',
                'title': policy['title'],
                'source': policy['source'],
                'action': 'è¯„ä¼°æ”¿ç­–å½±å“'
            })

    return report


# ============== CLI ==============

def print_results(results: List[Dict], title: str):
    """æ‰“å°ç»“æœ"""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print('='*60)

    if not results:
        print("  æ— ç»“æœ")
        return

    for i, r in enumerate(results[:15], 1):
        priority = r.get('priority', '')
        priority_icon = 'ğŸ”´' if priority == 'HIGH' else 'ğŸŸ¡' if priority == 'MEDIUM' else ''

        print(f"\n{i}. {priority_icon} {r.get('title', r.get('name', 'N/A'))}")

        if r.get('url'):
            print(f"   {r['url']}")

        if r.get('mentioned_companies'):
            print(f"   æåŠå…¬å¸: {', '.join(r['mentioned_companies'])}")

        if r.get('keywords_matched'):
            print(f"   åŒ¹é…å…³é”®è¯: {', '.join(r['keywords_matched'])}")

    print('\n' + '='*60)


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='æ”¿ç­–/é¢†å¯¼äººè¡Œç¨‹ç›‘æ§å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python policy_monitor.py --leader              # é¢†å¯¼äººè¡Œç¨‹
  python policy_monitor.py --leader-search       # æœç´¢é¢†å¯¼äººç§‘æŠ€è§†å¯Ÿ
  python policy_monitor.py --policy              # æ”¿ç­–æ–‡ä»¶
  python policy_monitor.py --founder å”æ°        # åˆ›å§‹äººè¿½è¸ª
  python policy_monitor.py --meeting             # åº§è°ˆä¼šå‚ä¸è€…
  python policy_monitor.py --daily               # æ¯æ—¥ç»¼åˆæŠ¥å‘Š
        """
    )

    parser.add_argument('--leader', action='store_true', help='é¢†å¯¼äººè¡Œç¨‹')
    parser.add_argument('--leader-search', action='store_true', help='æœç´¢é¢†å¯¼äººç§‘æŠ€è§†å¯Ÿ')
    parser.add_argument('--policy', action='store_true', help='æ”¿ç­–æ–‡ä»¶')
    parser.add_argument('--founder', type=str, help='åˆ›å§‹äººåŠ¨æ€è¿½è¸ª')
    parser.add_argument('--meeting', action='store_true', help='åº§è°ˆä¼šå‚ä¸è€…')
    parser.add_argument('--daily', action='store_true', help='æ¯æ—¥ç»¼åˆæŠ¥å‘Š')
    parser.add_argument('--json', action='store_true', help='JSONè¾“å‡º')

    args = parser.parse_args()

    if args.leader:
        results = get_leader_activities()
        if args.json:
            print(json.dumps(results, ensure_ascii=False, indent=2))
        else:
            print_results(results, "é¢†å¯¼äººè¿‘æœŸæ´»åŠ¨")

    elif args.leader_search:
        results = search_leader_tech_visits()
        if args.json:
            print(json.dumps(results, ensure_ascii=False, indent=2))
        else:
            print_results(results, "é¢†å¯¼äººç§‘æŠ€è§†å¯Ÿè®°å½•")

    elif args.policy:
        results = get_policy_updates()
        if args.json:
            print(json.dumps(results, ensure_ascii=False, indent=2))
        else:
            print_results(results, "è¿‘æœŸæ”¿ç­–æ–‡ä»¶")

    elif args.founder:
        print(f"ğŸ” è¿½è¸ªåˆ›å§‹äºº: {args.founder}")

        # é«˜å±‚ä¼šè®®å‚ä¸
        meetings = track_founder_meetings(args.founder)
        print_results(meetings, f"{args.founder} é«˜å±‚ä¼šè®®å‚ä¸è®°å½•")

        # è¿‘æœŸåŠ¨æ€
        news = get_founder_news(args.founder)
        print_results(news, f"{args.founder} è¿‘æœŸåŠ¨æ€")

    elif args.meeting:
        results = search_meeting_participants()
        if args.json:
            print(json.dumps(results, ensure_ascii=False, indent=2))
        else:
            print_results(results, "åº§è°ˆä¼šå‚ä¸è€…è®°å½•")

    elif args.daily:
        report = generate_daily_report()

        if args.json:
            print(json.dumps(report, ensure_ascii=False, indent=2, default=str))
        else:
            print(f"\nğŸ“Š æ¯æ—¥ç›‘æ§æŠ¥å‘Š ({report['date']})")
            print('='*60)

            if report['signals']:
                print("\nâš¡ ä¿¡å·æé†’:")
                for signal in report['signals']:
                    print(f"  [{signal['priority']}] {signal['type']}")
                    print(f"    {signal['title']}")
                    print(f"    å»ºè®®: {signal['action']}")

            print_results(report['leader_activities'], "é¢†å¯¼äººæ´»åŠ¨")
            print_results(report['policy_updates'], "æ”¿ç­–æ›´æ–°")

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
